{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3880c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfba7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda - NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# DNE\\Scripts\\Activate\n",
    "\n",
    "import os, re, csv, random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import warnings\n",
    "import transformers, datasets, logging\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"librosa\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"librosa\")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    message=\"Support for mismatched key_padding_mask and attn_mask is deprecated\"\n",
    ")\n",
    "warnings.filterwarnings('ignore')\n",
    "transformers.logging.set_verbosity_error()\n",
    "datasets.logging.set_verbosity_error()\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support,\n",
    "    confusion_matrix, roc_auc_score, average_precision_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "import librosa\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"Device:\", DEVICE, \"-\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f52dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache chuyển sang ổ D:\n",
      "D:\\\\AIP491\\\\huggingface_cache\n"
     ]
    }
   ],
   "source": [
    "import os, pathlib\n",
    "\n",
    "import os\n",
    "os.environ[\"HF_HOME\"] = r\"D:\\\\AIP491\\\\huggingface_cache\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = r\"D:\\\\AIP491\\\\huggingface_cache\\\\datasets\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = r\"D:\\\\AIP491\\\\huggingface_cache\\\\models\"\n",
    "os.environ[\"HF_HUB_CACHE\"] = r\"D:\\\\AIP491\\\\huggingface_cache\\\\hub\"\n",
    "\n",
    "os.environ[\"TMPDIR\"] = os.environ[\"TEMP\"] = os.environ[\"TMP\"] = r\"D:/AIP491/.tmp\"\n",
    "\n",
    "for p in [os.environ[\"HF_HOME\"], os.environ[\"HF_DATASETS_CACHE\"],\n",
    "          os.environ[\"HF_HUB_CACHE\"], os.environ[\"TRANSFORMERS_CACHE\"],\n",
    "          os.environ[\"TMPDIR\"]]:\n",
    "    pathlib.Path(p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Cache chuyển sang ổ D:\")\n",
    "print(os.environ[\"HF_HOME\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8076689c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8d8671da9a43cea8342f463f5abed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf87072a7b343f29298d76ae9d79792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1a68ac25af40f58c4814ef38044211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['path', 'label'],\n",
      "        num_rows: 18935\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['path', 'label'],\n",
      "        num_rows: 3025\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['path', 'label'],\n",
      "        num_rows: 4525\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "DATASETS_CACHE = os.environ[\"HF_DATASETS_CACHE\"]\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\n",
    "        \"train\":      \"D:\\\\AIP491\\\\DNE\\\\csv\\\\DNE_train.csv\",\n",
    "        \"validation\": \"D:\\\\AIP491\\\\DNE\\\\csv\\\\DNE_val.csv\",\n",
    "        \"test\":       \"D:\\\\AIP491\\\\DNE\\\\csv\\\\DNE_test.csv\"\n",
    "    },\n",
    "    cache_dir=DATASETS_CACHE,\n",
    ")\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a5aa252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6361cbe4382c41098afadb6924581613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18935 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663ea4cd3beb4cf1bce54025ec32f021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3025 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc50d29781d4511824a2c4cff8ffcfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4525 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def encode_label(example):\n",
    "    lbl = str(example[\"label\"]).strip().lower()\n",
    "    return {\"label\": 1 if lbl in [\"pos\", \"positive\", \"1\"] else 0}\n",
    "\n",
    "dataset = dataset.map(encode_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65dae0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6837afeefc04f08a9a6dde48b7165e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b7c7d5c6194efe84df5db774ede3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18935 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lỗi đọc D:\\\\AIP491\\\\DNE\\\\data\\\\CREMA_D\\\\audio\\\\1051_WSI_SAD_XX.wav: Error opening 'D:\\\\\\\\AIP491\\\\\\\\DNE\\\\\\\\data\\\\\\\\CREMA_D\\\\\\\\audio\\\\\\\\1051_WSI_SAD_XX.wav': Format not recognised.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da47b87fd24c465a91ff6d1888bbbaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3025 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6dd2773462410cb287c852d4884eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4525 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lỗi đọc D:\\\\AIP491\\\\DNE\\\\data\\\\CREMA_D\\\\audio\\\\1021_ITH_SAD_XX.wav: Error opening 'D:\\\\\\\\AIP491\\\\\\\\DNE\\\\\\\\data\\\\\\\\CREMA_D\\\\\\\\audio\\\\\\\\1021_ITH_SAD_XX.wav': Format not recognised.\n",
      "Done preprocessing.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "import numpy as np, soundfile as sf, librosa, datasets\n",
    "\n",
    "datasets.config.TORCHCODEC_AVAILABLE = False\n",
    "MODEL_NAME = \"facebook/wav2vec2-xls-r-300m\"\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(MODEL_NAME, cache_dir=os.environ[\"TRANSFORMERS_CACHE\"])\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "MAX_SECONDS = 8\n",
    "MAX_LEN = SAMPLING_RATE * MAX_SECONDS\n",
    "\n",
    "def preprocess(batch):\n",
    "    audio_path = batch[\"path\"]\n",
    "    try:\n",
    "        x, sr = sf.read(audio_path)\n",
    "        if x.ndim > 1:\n",
    "            x = x.mean(axis=1)\n",
    "        if sr != SAMPLING_RATE:\n",
    "            x = librosa.resample(x, orig_sr=sr, target_sr=SAMPLING_RATE)\n",
    "        x = x[:MAX_LEN].astype(np.float32)\n",
    "        features = feature_extractor(\n",
    "            x,\n",
    "            sampling_rate=SAMPLING_RATE,\n",
    "            padding=\"max_length\",\n",
    "            max_length=MAX_LEN,\n",
    "            truncation=True,\n",
    "            return_tensors=\"np\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_values\": features[\"input_values\"][0],\n",
    "            \"attention_mask\": features[\"attention_mask\"][0],\n",
    "            \"labels\": int(batch[\"label\"]),\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi đọc {audio_path}: {e}\")\n",
    "\n",
    "        dummy = np.zeros(MAX_LEN, dtype=np.float32)\n",
    "\n",
    "        features = feature_extractor(\n",
    "            dummy,\n",
    "            sampling_rate=SAMPLING_RATE,\n",
    "            padding=\"max_length\",\n",
    "            max_length=MAX_LEN,     \n",
    "            truncation=True,\n",
    "            return_tensors=\"np\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_values\": features[\"input_values\"][0],\n",
    "            \"attention_mask\": features[\"attention_mask\"][0],\n",
    "            \"labels\": int(batch[\"label\"]),\n",
    "        }\n",
    "\n",
    "dataset = dataset.map(preprocess, load_from_cache_file=False)\n",
    "dataset = dataset.with_format(\"torch\")\n",
    "\n",
    "print(\"Done preprocessing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410d31ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058ce33cde4549cf8eb6a985ff286fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0fa1e0cbae43e99e2e736b3255ef1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3b7a6eb2b64565b0567c8e2bc20015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69239d308f045a98bbefd97e72e53c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b520451f96804449821a2f561aca45c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fffd872781401e8c890588678c2973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4ed944618e4c08a02b091aaf0be250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForAudioClassification\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    cache_dir=os.environ[\"TRANSFORMERS_CACHE\"],\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "acc_metric = evaluate.load(\"accuracy\")\n",
    "prec_metric = evaluate.load(\"precision\")\n",
    "rec_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": acc_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"precision\": prec_metric.compute(predictions=preds, references=labels)[\"precision\"],\n",
    "        \"recall\": rec_metric.compute(predictions=preds, references=labels)[\"recall\"],\n",
    "        \"f1\": f1_metric.compute(predictions=preds, references=labels)[\"f1\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4fd72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random\n",
    "import wandb\n",
    "import torch\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class WandbEpochLogger(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gpu_name = \"CPU\"\n",
    "        self.gpu_mem_total = 0\n",
    "        if torch.cuda.is_available():\n",
    "            self.gpu_name = torch.cuda.get_device_name(0)\n",
    "            mem_info = torch.cuda.mem_get_info(device=0)\n",
    "            self.gpu_mem_total = mem_info[1] / (1024**3)\n",
    "\n",
    "    def get_gpu_stats(self):\n",
    "        if torch.cuda.is_available():\n",
    "            mem_info = torch.cuda.mem_get_info(device=0)\n",
    "            mem_free = mem_info[0] / (1024**3)\n",
    "            mem_total = mem_info[1] / (1024**3)\n",
    "            mem_used = mem_total - mem_free\n",
    "            usage_pct = mem_used / mem_total * 100\n",
    "            return mem_used, mem_total, usage_pct\n",
    "        else:\n",
    "            return 0, 0, 0\n",
    "\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        run_name = f\"wav2vec2\"\n",
    "        wandb.init(\n",
    "            project=\"DNE_baseline\", ######################################################################################################\n",
    "            name=run_name,\n",
    "            config=args.to_dict()\n",
    "        )\n",
    "        print(f\"Logging W&B bắt đầu | Thiết bị: {self.gpu_name}\")\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, metrics=None, **kwargs):\n",
    "        if metrics:\n",
    "            epoch = int(state.epoch)\n",
    "            gpu_mem_used, gpu_mem_total, gpu_usage_pct = self.get_gpu_stats()\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch,\n",
    "                \"train/loss\": metrics.get(\"loss\"),\n",
    "                \"eval/loss\": metrics.get(\"eval_loss\"),\n",
    "                \"eval/accuracy\": metrics.get(\"eval_accuracy\"),\n",
    "                \"eval/f1\": metrics.get(\"eval_f1\"),\n",
    "                \"gpu/name\": self.gpu_name,\n",
    "                \"gpu/memory_used_GB\": gpu_mem_used,\n",
    "                \"gpu/memory_total_GB\": gpu_mem_total,\n",
    "                \"gpu/memory_usage_%\": gpu_usage_pct,\n",
    "            })\n",
    "            print(f\"Epoch {epoch}: \"\n",
    "                  f\"F1={metrics.get('eval_f1'):.4f}, \"\n",
    "                  f\"Acc={metrics.get('eval_accuracy'):.4f}, \"\n",
    "                  f\"GPU={gpu_usage_pct:.1f}% VRAM ({gpu_mem_used:.2f}/{gpu_mem_total:.2f} GB)\")\n",
    "\n",
    "    def on_save(self, args, state, control, **kwargs):\n",
    "        epoch = int(state.epoch)\n",
    "        default_ckpt = os.path.join(args.output_dir, f\"checkpoint-{state.global_step}\")\n",
    "        new_ckpt = os.path.join(args.output_dir, f\"checkpoint-epoch-{epoch:02d}\")\n",
    "        if os.path.exists(default_ckpt):\n",
    "            try:\n",
    "                os.rename(default_ckpt, new_ckpt)\n",
    "                # print(f\"Đổi tên checkpoint thành: {new_ckpt}\")\n",
    "                wandb.log({\"checkpoint_saved_epoch\": epoch})\n",
    "            except Exception as e:\n",
    "                print(f\"Không thể đổi tên checkpoint: {e}\")\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        wandb.finish()\n",
    "        print(\"xong\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d471ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers.trainer_callback import TrainerCallback\n",
    "\n",
    "\n",
    "OUTPUT_DIR = \"D:/AIP491/DNE/check_points_baseline/wav2vec2\"\n",
    "EPOCHS = 5 \n",
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    gradient_accumulation_steps=2,\n",
    "    warmup_ratio=0.05,\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_steps= 500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    disable_tqdm=False,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[WandbEpochLogger()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12c1634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ['pos' 'neg']\n",
      "label\n",
      "pos    11222\n",
      "neg     7713\n",
      "Name: count, dtype: int64\n",
      "val: ['neg' 'pos']\n",
      "label\n",
      "pos    1550\n",
      "neg    1475\n",
      "Name: count, dtype: int64\n",
      "test ['pos' 'neg']\n",
      "label\n",
      "pos    2703\n",
      "neg    1822\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "link_csv_train = pd.read_csv('D:\\\\AIP491\\\\DNE\\\\csv\\\\DNE_train.csv')\n",
    "print('train:',link_csv_train['label'].unique())\n",
    "print(link_csv_train['label'].value_counts())\n",
    "link_csv_val = pd.read_csv('D:\\\\AIP491\\\\DNE\\\\csv\\\\DNE_val.csv')\n",
    "print('val:',link_csv_val['label'].unique())\n",
    "print(link_csv_val['label'].value_counts())\n",
    "link_csv_test = pd.read_csv('D:\\\\AIP491\\\\DNE\\\\csv\\\\DNE_test.csv')\n",
    "print('test', link_csv_test['label'].unique())\n",
    "print(link_csv_test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4d40161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 315,701,634\n",
      "Trainable parameters: 315,701,634\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "total, trainable = count_parameters(model)\n",
    "\n",
    "print(f\"Total parameters: {total:,}\")\n",
    "print(f\"Trainable parameters: {trainable:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fc90e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzidanepm\u001b[0m (\u001b[33mzidanepm-fpt-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\AIP491\\DNE\\code\\baseline\\wav2vec2-xls-r-300m\\wandb\\run-20251223_221440-e8brti63</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zidanepm-fpt-university/huggingface/runs/e8brti63' target=\"_blank\">worldly-galaxy-4</a></strong> to <a href='https://wandb.ai/zidanepm-fpt-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zidanepm-fpt-university/huggingface' target=\"_blank\">https://wandb.ai/zidanepm-fpt-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zidanepm-fpt-university/huggingface/runs/e8brti63' target=\"_blank\">https://wandb.ai/zidanepm-fpt-university/huggingface/runs/e8brti63</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worldly-galaxy-4</strong> at: <a href='https://wandb.ai/zidanepm-fpt-university/huggingface/runs/e8brti63' target=\"_blank\">https://wandb.ai/zidanepm-fpt-university/huggingface/runs/e8brti63</a><br> View project at: <a href='https://wandb.ai/zidanepm-fpt-university/huggingface' target=\"_blank\">https://wandb.ai/zidanepm-fpt-university/huggingface</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251223_221440-e8brti63\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\AIP491\\DNE\\code\\baseline\\wav2vec2-xls-r-300m\\wandb\\run-20251223_221443-ue0r66hd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zidanepm-fpt-university/DNE_baseline/runs/ue0r66hd' target=\"_blank\">wav2vec2</a></strong> to <a href='https://wandb.ai/zidanepm-fpt-university/DNE_baseline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zidanepm-fpt-university/DNE_baseline' target=\"_blank\">https://wandb.ai/zidanepm-fpt-university/DNE_baseline</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zidanepm-fpt-university/DNE_baseline/runs/ue0r66hd' target=\"_blank\">https://wandb.ai/zidanepm-fpt-university/DNE_baseline/runs/ue0r66hd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging W&B bắt đầu | Thiết bị: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11835' max='11835' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11835/11835 103:46:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.560700</td>\n",
       "      <td>0.573850</td>\n",
       "      <td>0.708430</td>\n",
       "      <td>0.758514</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>0.554936</td>\n",
       "      <td>0.730909</td>\n",
       "      <td>0.788401</td>\n",
       "      <td>0.649032</td>\n",
       "      <td>0.711960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>0.597698</td>\n",
       "      <td>0.729256</td>\n",
       "      <td>0.800329</td>\n",
       "      <td>0.628387</td>\n",
       "      <td>0.704012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.484600</td>\n",
       "      <td>0.546488</td>\n",
       "      <td>0.764959</td>\n",
       "      <td>0.795215</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.760687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.451700</td>\n",
       "      <td>0.533582</td>\n",
       "      <td>0.771570</td>\n",
       "      <td>0.815114</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.762788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>checkpoint_saved_epoch</td><td>▁▃▅▆█</td></tr><tr><td>eval/accuracy</td><td>▁▃▃▇█</td></tr><tr><td>eval/f1</td><td>▁▃▂██</td></tr><tr><td>eval/loss</td><td>▅▃█▂▁</td></tr><tr><td>eval/precision</td><td>▁▅▆▆█</td></tr><tr><td>eval/recall</td><td>▁▂▁█▇</td></tr><tr><td>eval/runtime</td><td>▁▆▂█▃</td></tr><tr><td>eval/samples_per_second</td><td>█▃▇▁▆</td></tr><tr><td>eval/steps_per_second</td><td>█▃█▁█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>checkpoint_saved_epoch</td><td>5</td></tr><tr><td>eval/accuracy</td><td>0.77157</td></tr><tr><td>eval/f1</td><td>0.76279</td></tr><tr><td>eval/loss</td><td>0.53358</td></tr><tr><td>eval/precision</td><td>0.81511</td></tr><tr><td>eval/recall</td><td>0.71677</td></tr><tr><td>eval/runtime</td><td>3092.5948</td></tr><tr><td>eval/samples_per_second</td><td>0.978</td></tr><tr><td>eval/steps_per_second</td><td>0.245</td></tr><tr><td>total_flos</td><td>2.29547920887936e+19</td></tr><tr><td>+9</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wav2vec2</strong> at: <a href='https://wandb.ai/zidanepm-fpt-university/DNE_baseline/runs/ue0r66hd' target=\"_blank\">https://wandb.ai/zidanepm-fpt-university/DNE_baseline/runs/ue0r66hd</a><br> View project at: <a href='https://wandb.ai/zidanepm-fpt-university/DNE_baseline' target=\"_blank\">https://wandb.ai/zidanepm-fpt-university/DNE_baseline</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251223_221443-ue0r66hd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xong\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11835, training_loss=0.5123876042239113, metrics={'train_runtime': 373621.9648, 'train_samples_per_second': 0.253, 'train_steps_per_second': 0.032, 'total_flos': 2.29547920887936e+19, 'train_loss': 0.5123876042239113, 'epoch': 5.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "# # nvidia-smi -l 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2609244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run([\n",
    "    \"wandb\", \"sync\",\n",
    "    r\"D:\\\\AIP491\\\\DNE\\\\code\\\\baseline\\\\wav2vec2-xls-r-300m\\\\wandb\\\\run-20251223_221443-ue0r66hd\"\n",
    "], check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18ef8ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, time\n",
    "# time.sleep(300)\n",
    "# os.system('shutdown /s /t 0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DNE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
